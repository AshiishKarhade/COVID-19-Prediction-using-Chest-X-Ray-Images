# -*- coding: utf-8 -*-
"""covid-keras.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UplRBZ7FyyI6QPKU6Dp8LFVtq17kUQGa
"""

!pip install opendatasets --quiet
import opendatasets as od

import matplotlib.pyplot as plt
import numpy as np
import os
import shutil
import keras
from keras import layers
from keras.preprocessing import image
from keras.layers import Dense, GlobalAveragePooling2D
from keras.callbacks import CSVLogger
from keras.utils.np_utils import to_categorical
from keras.models import Sequential
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from keras.applications.resnet import ResNet101
from keras.layers.convolutional import Conv2D, MaxPooling2D

KEY='a47e6c1d4d1f552615865491be5c52d1'
URL = 'https://www.kaggle.com/tawsifurrahman/covid19-radiography-database'
data = od.download_kaggle_dataset(URL, data_dir='./')

# Remove unwanted files from directory to another
!mv /content/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID.metadata.xlsx /content/
!mv /content/covid19-radiography-database/COVID-19_Radiography_Dataset/Lung_Opacity.metadata.xlsx /content/
!mv /content/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal.metadata.xlsx /content/
!mv /content/covid19-radiography-database/COVID-19_Radiography_Dataset/README.md.txt /content/
!mv /content/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral\ Pneumonia.metadata.xlsx /content/
#shutil.move('/content/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia.metadata.xlsx', '/content/')

# make necessary folders
os.mkdir('/content/covid19-radiography-database/TEST')
os.mkdir('/content/covid19-radiography-database/TEST/COVID')
os.mkdir('/content/covid19-radiography-database/TEST/Lung_Opacity')
os.mkdir('/content/covid19-radiography-database/TEST/Normal')
os.mkdir('/content/covid19-radiography-database/TEST/Viral Pneumonia')

### FIRST TURN the DIRECTORIES into TRAIN, TEST, VAL DIRECTORIES
TEST_SIZE = 0.1

test_path = '/content/covid19-radiography-database/TEST'
home_path = '/content/covid19-radiography-database/COVID-19_Radiography_Dataset'
for folder in os.listdir(home_path):
    directory_list = os.listdir(home_path+'/'+folder)
    num = len(directory_list)
    ends = int(TEST_SIZE * num)
    subset = directory_list[ends::-1]
    #print(len(subset))
    for image in subset:
        #print(os.path.join(test_path, os.path.join('/', folder)))
        img_path = home_path + '/' + folder + '/' + image
        dest_path = test_path + '/' + folder
        shutil.move(img_path, dest_path)

os.rename('/content/covid19-radiography-database/COVID-19_Radiography_Dataset', '/content/covid19-radiography-database/TRAIN')

train_dir = '/content/covid19-radiography-database/TRAIN'
test_dir = '/content/covid19-radiography-database/TEST'

datagen = ImageDataGenerator(rescale = 1./255,)
#pixel_value = [0, 255] -> [0, 1]

train_dataset = datagen.flow_from_directory(
    train_dir,
    target_size=(224,224),
    class_mode='categorical',
    shuffle=True
)

test_dataset = datagen.flow_from_directory(
    test_dir, 
    target_size=(224,224),
    class_mode='categorical',
    shuffle=True
)

test_dataset.class_indices

from keras import backend as K

def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_m(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))
#print(K)

"""## Custom CNN Model"""

model = Sequential([
                    # BLOCK 1
                    Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = (224, 224, 3)),
                    Conv2D(64, kernel_size=(3,3), activation='relu'),
                    MaxPooling2D(pool_size=(2,2)),
                    Dropout(0.25),
                    # BLOCK 2
                    Conv2D(128, kernel_size=(3,3), activation='relu'),
                    MaxPooling2D(pool_size=(2,2)),
                    Dropout(0.25),
                    # BLOCK 3
                    Conv2D(128, kernel_size=(3,3), activation='relu'),
                    MaxPooling2D(pool_size=(2,2)),
                    Dropout(0.25),
                    # BLOCK 4
                    Conv2D(264, kernel_size=(3,3), activation='relu'),
                    MaxPooling2D(pool_size=(2,2)),
                    Dropout(0.25),
                    # block 5
                    Flatten(),
                    Dense(64, activation='relu'),
                    Dropout(0.5),
                    Dense(4, activation='softmax')
])



model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy',f1_m,precision_m, recall_m])

model.summary()

history = model.fit(
    train_dataset, 
    epochs=5,
    validation_data = test_dataset, 
    verbose=2
)

loss, accuracy, f1_score, precision, recall = model.evaluate(test_dataset, verbose=0)
print("loss: {:.2f}, accuracy: {:.2f}, f1_score: {:.2f}, precision: {:.2f}, recall: {:.2f}".format(loss, accuracy, f1_score, precision, recall))

print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('custom cnn model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('custom_cnn_accuracy')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('custom cnn model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.savefig('custom_cnn_loss')
plt.show()



"""## VGG19"""

from keras.applications.vgg19 import VGG19

vgg19 = VGG19(weights='imagenet', include_top=False)

vgg19.summary()

x = vgg19.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(4, activation='softmax')(x)

model = Model(inputs=vgg19.input, outputs=predictions)

for layer in vgg19.layers:
    layer.trainable = False

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy',f1_m,precision_m, recall_m])

history2 = model.fit(
    train_dataset, 
    epochs=5,
    validation_data = test_dataset, 
    verbose=2
)

loss, accuracy, f1_score, precision, recall = model.evaluate(test_dataset, verbose=0)
print("loss: {:.2f}, accuracy: {:.2f}, f1_score: {:.2f}, precision: {:.2f}, recall: {:.2f}".format(loss, accuracy, f1_score, precision, recall))

print(history2.history.keys())
# summarize history for accuracy
plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('VGG19 model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('vgg19_accuracy')
plt.show()

# summarize history for loss
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('VGG19 model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.savefig('vgg19_loss')
plt.show()



"""## InceptionV3"""

from keras.applications.inception_v3 import InceptionV3

inceptionv3 = InceptionV3(include_top=False, weights='imagenet')

inceptionv3.summary()

x = inceptionv3.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(4, activation='softmax')(x)

model = Model(inputs=inceptionv3.input, outputs=predictions)

model.summary()

for layer in inceptionv3.layers:
    layer.trainable = False

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy',f1_m,precision_m, recall_m])

history3 = model.fit(
    train_dataset, 
    epochs=5,
    validation_data = test_dataset, 
    verbose=2
)

loss, accuracy, f1_score, precision, recall = model.evaluate(test_dataset, verbose=0)
print("loss: {:.2f}, accuracy: {:.2f}, f1_score: {:.2f}, precision: {:.2f}, recall: {:.2f}".format(loss, accuracy, f1_score, precision, recall))

print(history3.history.keys())
# summarize history for accuracy
plt.plot(history3.history['accuracy'])
plt.plot(history3.history['val_accuracy'])
plt.title('InceptionV3 model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('inceptionv3_accuracy')
plt.show()

# summarize history for loss
plt.plot(history3.history['loss'])
plt.plot(history3.history['val_loss'])
plt.title('InceptionV3 model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.savefig('inceptionv3_loss')
plt.show()



"""## InceptionResNetV2"""

from keras.applications.inception_resnet_v2 import InceptionResNetV2

inception_resnet = InceptionResNetV2(include_top=False, weights='imagenet')

inception_resnet.summary()

x = inception_resnet.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(4, activation='softmax')(x)

model = Model(inputs=inception_resnet.input, outputs=predictions)

model.summary()

for layer in inception_resnet.layers:
    layer.trainable = False

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy',f1_m,precision_m, recall_m])

history4 = model.fit(
    train_dataset, 
    epochs=5,
    validation_data = test_dataset, 
    verbose=2
)

loss, accuracy, f1_score, precision, recall = model.evaluate(test_dataset, verbose=0)
print("loss: {:.2f}, accuracy: {:.2f}, f1_score: {:.2f}, precision: {:.2f}, recall: {:.2f}".format(loss, accuracy, f1_score, precision, recall))

print(history4.history.keys())
# summarize history for accuracy
plt.plot(history4.history['accuracy'])
plt.plot(history4.history['val_accuracy'])
plt.title('Inception Resnet model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('Inception-resnet_accuracy')
plt.show()

# summarize history for loss
plt.plot(history4.history['loss'])
plt.plot(history4.history['val_loss'])
plt.title('Inception Resnet model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.savefig('inception-resnet_loss')
plt.show()



"""## ResNet152V2"""

from keras.applications.resnet_v2 import ResNet152V2

resnet152 = ResNet152V2(include_top=False, weights='imagenet')

resnet152.summary()

x = resnet152.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(4, activation='softmax')(x)

model = Model(inputs=resnet152.input, outputs=predictions)

for layer in resnet152.layers:
    layer.trainable = False

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy',f1_m,precision_m, recall_m])

history5 = model.fit(
    train_dataset, 
    epochs=5,
    validation_data = test_dataset, 
    verbose=2
)

loss, accuracy, f1_score, precision, recall = model.evaluate(test_dataset, verbose=0)
print("loss: {:.2f}, accuracy: {:.2f}, f1_score: {:.2f}, precision: {:.2f}, recall: {:.2f}".format(loss, accuracy, f1_score, precision, recall))

model.save('resnet152v2e5v1.h5')

print(history5.history.keys())
# summarize history for accuracy
plt.plot(history5.history['accuracy'])
plt.plot(history5.history['val_accuracy'])
plt.title('Resnet152V2 model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('resnet152_accuracy')
plt.show()

# summarize history for loss
plt.plot(history5.history['loss'])
plt.plot(history5.history['val_loss'])
plt.title('Resnet152V2 model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.savefig('resnet152_loss')
plt.show()

"""## Xception Net"""

from keras.applications.xception import Xception

xcept = Xception(include_top=False, weights='imagenet')

xcept.summary()

x = xcept.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(4, activation='softmax')(x)

model = Model(inputs=xcept.input, outputs=predictions)

for layer in xcept.layers:
    layer.trainable = False

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy',f1_m,precision_m, recall_m])

history6 = model.fit(
    train_dataset, 
    epochs=5,
    validation_data = test_dataset, 
    verbose=2
)

loss, accuracy, f1_score, precision, recall = model.evaluate(test_dataset, verbose=0)
print("loss: {:.2f}, accuracy: {:.2f}, f1_score: {:.2f}, precision: {:.2f}, recall: {:.2f}".format(loss, accuracy, f1_score, precision, recall))

print(history6.history.keys())
# summarize history for accuracy
plt.plot(history6.history['accuracy'])
plt.plot(history6.history['val_accuracy'])
plt.title('Xception model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('xception_accuracy')
plt.show()

# summarize history for loss
plt.plot(history6.history['loss'])
plt.plot(history6.history['val_loss'])
plt.title('Xception model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.savefig('xception_loss')
plt.show()



"""# Comparison of all models"""



# F1 SCORES
cnn_f1 = [0.8592, 0.8651, 0.8570, 0.8822, 0.8825]
vgg19_f1 = [0.7253, 0.7984, 0.8308, 0.8303, 0.8366]
inceptionv3_f1 = [0.8067, 0.8215, 0.8379, 0.8320, 0.8540]
inc_resnet_f1 = [0.7399, 0.7941, 0.8089, 0.8177, 0.8283]
resnet_f1 = [0.8532, 0.8535, 0.8764, 0.8719, 0.8812]
xception_f1 = [0.7969, 0.8299, 0.8329, 0.8380, 0.8460]

# Validation Accuracy
cnn_acc = [0.8603, 0.8674, 0.8636, 0.8858, 0.8806]
vgg19_acc = [0.7447, 0.8145, 0.8339, 0.8367, 0.8334]
inceptionv3_acc = [0.8112, 0.8226, 0.8372, 0.8339, 0.8523]
inc_resnet_acc = [0.7504, 0.7995, 0.8123, 0.8207, 0.8321]
resnet_acc = [0.8589, 0.8570, 0.8759, 0.8697, 0.8834]
xception_acc = [0.8013, 0.8311, 0.8358, 0.8362, 0.8485]

import pandas as pd
cols = ['CNN', 'VGG19', 'InceptionV3', 'Inception-Resnet', 'Resnet152', 'Xception']
idxs = ['Epoch:1','Epoch:2','Epoch:3','Epoch:4','Epoch:5']

f1_scores = pd.DataFrame(zip(cnn_f1, vgg19_f1, inceptionv3_f1, inc_resnet_f1, resnet_f1, xception_f1), columns=cols, index=idxs)
f1_scores

val_scores = pd.DataFrame(zip(cnn_acc, vgg19_acc, inceptionv3_acc, inc_resnet_acc, resnet_acc, xception_acc), columns=cols, index=idxs)
val_scores



"""As we can see, ResNet152V2 performs very well than other models for our problem. We will be selecting Resnet152V2 as our final model"""

